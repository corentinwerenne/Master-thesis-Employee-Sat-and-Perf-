{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702e41c9-ec35-4efe-b9ca-206d97d75559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests #For requesting html\n",
    "import re #For regular expressions\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import logging\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da2233b-08aa-4e74-815d-445bd8c2e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For logging\n",
    "# logger = logging.getLogger()\n",
    "# fhandler = logging.FileHandler(filename='reviews.log', mode='a')\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# fhandler.setFormatter(formatter)\n",
    "# logger.addHandler(fhandler)\n",
    "# logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c537c04-b987-4cf1-a9ef-002016a01392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status():\n",
    "    \"\"\"\n",
    "    Reads the excel with the company names, links, modified links, how many options there were at search\n",
    "    and how much has been scraped yet and returns those different lists\n",
    "    \"\"\"\n",
    "    wb = load_workbook('status.xlsx')\n",
    "    sheet = wb.worksheets[0]\n",
    "    companies = sheet['A']\n",
    "    number_options = sheet['B']\n",
    "    links = sheet['C']\n",
    "    pages = sheet['E']\n",
    "    \n",
    "    return companies, number_options, links, pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6479a2f1-b7a6-4387-b1fe-a923626bad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cells_to_list(cells):\n",
    "    \"\"\"\n",
    "    Convert openpyxl format cells to strings\n",
    "    \"\"\"\n",
    "    cells_list = []\n",
    "    for cell in cells:\n",
    "        cells_list.append(cell.value)\n",
    "    return cells_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc1543d-5443-43dc-b0a5-9e76ac37e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials\n",
    "f = open('credentials.txt', 'r') #Opens the credentials.txt file for reading\n",
    "credentials = f.readlines() #Returns a list of strings with cookie and user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af1ba30-bb43-4d9c-8132-10f6cd869c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    'cookie': credentials[0].replace('\\n', ''),\n",
    "    'authority': \"www.glassdoor.com\",\n",
    "    'accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    'accept-language': \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    'cache-control': \"max-age=0\",\n",
    "    'referer': \"https://nl.glassdoor.be/\",\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"101\", \"Google Chrome\";v=\"101\"',\n",
    "    'sec-ch-ua-mobile': \"?0\",\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': \"document\",\n",
    "    'sec-fetch-mode': \"navigate\",\n",
    "    'sec-fetch-site': \"same-origin\",\n",
    "    'sec-fetch-user': \"?1\",\n",
    "    'upgrade-insecure-requests': \"1\",\n",
    "    'user-agent': credentials[1].replace('\\n', '')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead08132-62db-4399-9171-859b3c4d90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses\n",
    "def get_response(url):\n",
    "    \"\"\"\n",
    "    returns glassdoor review query for a url converted to raw string\n",
    "    \"\"\"\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers)\n",
    "    raw_response = repr(response.text)\n",
    "    return raw_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a36f8b-7a17-4e90-b6cc-fc401a06dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts reviews out of response\n",
    "def get_reviews(response):\n",
    "    review_pattern = re.compile(r'{\\\"__typename\\\":\\\"EmployerReview\\\".+?\\\"translationMethod\\\":.+?}')\n",
    "    matches = review_pattern.finditer(response)\n",
    "    reviews = []\n",
    "    for i, match in enumerate(matches):\n",
    "        reviews.append(match.group(0))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1ae481-7305-4583-bc0d-3bc3e200ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_review(review):\n",
    "    \"\"\"\n",
    "    Expects a review build like a string dictionnary, extracts each feature out of a single review, returns a proper dictionary\n",
    "    \"\"\"\n",
    "    review_id = re.compile(r'\\\"reviewId\\\":(.+?),\\\"reviewDateTime\"').search(review).group(1)\n",
    "    review_datetime = re.compile(r'\\\"reviewDateTime\\\":\\\"(.+?)\\\",\\\"ratingOverall\\\"').search(review).group(1)\n",
    "    rating_overall = re.compile(r'\\\"ratingOverall\\\":(.+?),\\\"ratingCeo\\\"').search(review).group(1)\n",
    "    rating_ceo = re.compile(r'\\\"ratingCeo\\\":(.+?),\\\"ratingBusinessOutlook\\\"').search(review).group(1)\n",
    "    rating_businessoutlook = re.compile(r'\\\"ratingBusinessOutlook\\\":(.+?),\\\"ratingWorkLifeBalance\\\"').search(review).group(1)\n",
    "    rating_worklife_balance = re.compile(r'\\\"ratingWorkLifeBalance\\\":(.+?),\\\"ratingCultureAndValues\\\"').search(review).group(1)\n",
    "    rating_culture_values = re.compile(r'\\\"ratingCultureAndValues\\\":(.+?),\\\"ratingDiversityAndInclusion\\\"').search(review).group(1)\n",
    "    rating_diversity_inclusion = re.compile(r'\\\"ratingDiversityAndInclusion\\\":(.+?),\\\"ratingSeniorLeadership\\\"').search(review).group(1)\n",
    "    rating_senior_leadership = re.compile(r'\\\"ratingSeniorLeadership\\\":(.+?),\\\"ratingRecommendToFriend\\\"').search(review).group(1)\n",
    "    rating_recommend_friend = re.compile(r'\\\"ratingRecommendToFriend\\\":(.+?),\\\"ratingCareerOpportunities\\\"').search(review).group(1)\n",
    "    rating_career_opport = re.compile(r'\\\"ratingCareerOpportunities\\\":(.+?),\\\"ratingCompensationAndBenefits\\\"').search(review).group(1)\n",
    "    rating_compensation_benefits = re.compile(r'\\\"ratingCompensationAndBenefits\\\":(.+?),\\\"employer\\\"').search(review).group(1)\n",
    "    is_current_job = re.compile(r'\\\"isCurrentJob\\\":(.+?),\\\"lengthOfEmployment\\\"').search(review).group(1)\n",
    "    length_employment = re.compile(r'\\\"lengthOfEmployment\\\":(.+?),\\\"employmentStatus\\\"').search(review).group(1)\n",
    "    employment_status = re.compile(r'\"employmentStatus\":(.+?),\"jobEndingYear\"').search(review).group(1)\n",
    "    job_ending_year = re.compile(r'\"jobEndingYear\":(.+?),\"jobTitle\"').search(review).group(1)\n",
    "    pros = re.compile(r'\\\"pros\\\":\\\"(.+?)\\\",\\\"prosOriginal\\\":').search(review).group(1)\n",
    "    cons = re.compile(r'\\\"cons\\\":\\\"(.+?)\\\",\\\"consOriginal\\\":').search(review).group(1)\n",
    "    advice = re.compile(r'\\\"advice\\\":(.+?),\\\"adviceOriginal\\\":').search(review).group(1)\n",
    "    count_helpful = re.compile(r'\\\"countHelpful\\\":(.+?),\\\"countNotHelpful\\\":').search(review).group(1)\n",
    "    count_nothelpful = re.compile(r'\\\"countNotHelpful\\\":(.+?),\\\"employerResponses\\\"').search(review).group(1)\n",
    "    language_id = re.compile(r'\\\"languageId\\\":(.+?),\\\"translationMethod\\\"').search(review).group(1)\n",
    "    post_title = re.compile(r'\\\"summary\\\":(.+?),\\\"summaryOriginal\\\"').search(review).group(1)\n",
    "\n",
    "    \n",
    "    review_data = {'review_id': review_id,\n",
    "               'post_title': post_title,\n",
    "               'review_datetime': review_datetime,\n",
    "               'review_overall': rating_overall,\n",
    "               'rating_ceo': rating_ceo,\n",
    "               'rating_businessoutlook': rating_businessoutlook,\n",
    "               'rating_worklifebalance': rating_worklife_balance,\n",
    "               'rating_culture_values': rating_culture_values,\n",
    "               'rating_diversity_inclusion': rating_diversity_inclusion,\n",
    "               'rating_senior_leadership': rating_senior_leadership,\n",
    "               'rating_recommend_friend': rating_recommend_friend,\n",
    "               'rating_career_opport': rating_career_opport,\n",
    "               'rating_compensation_benefits': rating_compensation_benefits,\n",
    "               'is_current_job': is_current_job,\n",
    "               'length_employment': length_employment,\n",
    "               'employment_status': employment_status,\n",
    "               'job_ending_year': job_ending_year,\n",
    "               'pros': pros,\n",
    "               'cons': cons,\n",
    "               'advice': advice,\n",
    "               'count_helpful': count_helpful,\n",
    "               'count_nothelpful': count_nothelpful,\n",
    "               'language_id': language_id}\n",
    "    \n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43eee07a-3c05-479e-8712-2b0f4c50ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datestr_to_str(date_str):\n",
    "    \"\"\"\n",
    "    Convert a string with format 2022-06-13T05:07:07.813 to a datetime object\n",
    "    \"\"\"\n",
    "    t_index = date_str.index('T')\n",
    "    date = date_str[:t_index]\n",
    "    date_time = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9f0a29-9746-4b2b-93a0-874200810009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_df(url, i, company, max_date='2017-01-01', s=5, page=1):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Base url with no filter except maybe location.\n",
    "        ex: 'https://www.glassdoor.com/Reviews/Deloitte-Reviews-E2763.htm'\n",
    "    max_date : string\n",
    "        Defines how far the scraper will go in the past. \n",
    "        WARNING: This features only works properly if sorted by most recent\n",
    "        ex: '2022-05-09'\n",
    "    company : string\n",
    "        Defines how the csv's will be named before saved\n",
    "    s : int\n",
    "        Defines how much pause between each request to the server. The lower the faster\n",
    "        but also the more at risk of getting banned.\n",
    "    page : str\n",
    "        Defines at what page the scraper will start\n",
    "    i : int\n",
    "        In what position the company is in the excel\n",
    "        Is needed to save the status of scraping\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of dictionaries containing the information extracted from the reviews.\n",
    "\n",
    "    \"\"\"\n",
    "    # Pattern to extract the reviews out of the javascript response\n",
    "    review_pattern = re.compile(r'{\\\"__typename\\\":\\\"EmployerReview\\\".+?\\\"translationMethod\\\":.+?}')\n",
    "    \n",
    "    # Transform string date into datetime object for comparison\n",
    "    max_date = datetime.datetime.strptime(max_date, '%Y-%m-%d')\n",
    "    \n",
    "    # Useful later to loop over pages\n",
    "    htm_index = url.index('.htm')\n",
    "    \n",
    "    # Intializing list for storing reviews\n",
    "    reviews_parsed = []\n",
    "    \n",
    "    # Extract from first page\n",
    "    urlp = url[:htm_index] + '_P' + str(page) + url[htm_index:]  # Creates the url for the first page\n",
    "    response = get_response(urlp)\n",
    "    reviews = get_reviews(response)\n",
    "    for review in reviews:\n",
    "        parsed_review = extract_from_review(review)\n",
    "        reviews_parsed.append(parsed_review) #Gets all the reviews in a list\n",
    "    \n",
    "    clean_company_name = company.replace('.', '').replace(' ', '').replace('/', '')\n",
    "    \n",
    "    \n",
    "    # Define latest date\n",
    "    if reviews: # true if list not empty\n",
    "        latest_date = reviews_parsed[-1]['review_datetime'] # Takes the data of the last review of the page\n",
    "        \n",
    "        time.sleep(random.uniform(s-1, s+1))   \n",
    "        # Extracts from following pages\n",
    "        while datestr_to_str(latest_date) > max_date: # Evaluates true if we haven't passed the max date\n",
    "            page +=1\n",
    "            urlp = url[:htm_index] + '_P' + str(page) + url[htm_index:]  # Creates the url for the first page\n",
    "            time.sleep(random.uniform(s-1, s+1))\n",
    "            response = get_response(urlp)\n",
    "            reviews = get_reviews(response)\n",
    "            for review in reviews:\n",
    "                parsed_review = extract_from_review(review)\n",
    "                reviews_parsed.append(parsed_review) #Gets all the reviews in a list\n",
    "                \n",
    "            if reviews: \n",
    "                latest_date = reviews_parsed[-1]['review_datetime']\n",
    "                if page % 50 == 0: # Saves the reviews each multiple of ten pages\n",
    "                    #pd.DataFrame(reviews_parsed[:-2]).to_csv(f'../../data/{company}_{page}.csv')\n",
    "                    pd.DataFrame(reviews_parsed).to_csv(f'reviews/{clean_company_name}_{page}.csv', index=False) #Save\n",
    "                    sheet.cell(row=i+1, column=5).value=page\n",
    "                    wb.save('status.xlsx')\n",
    "                    reviews_parsed = [] #Delete\n",
    "                    logging.info(f'{urlp} successfully saved')\n",
    "                    time.sleep(random.uniform(80, 130)) #Long break\n",
    "                else: \n",
    "                    continue\n",
    "            else:\n",
    "                break\n",
    "    else: # If the list is empty, we initialize a variable at unimportant date just to avoid crash later on\n",
    "        latest_date = '2000-01-01T05:07:07.813' \n",
    "        \n",
    "    \n",
    "        \n",
    "    # To save what's left, duplicates likely from the last page scraped\n",
    "    pd.DataFrame(reviews_parsed).to_csv(f'reviews/{clean_company_name}_{page}.csv', index=False)\n",
    "    sheet.cell(row=i+1, column=5).value='done'\n",
    "    wb.save('status.xlsx')\n",
    "    logging.info(f'{urlp} successfully saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d275a6-cb3a-41b8-b682-0a18f33dab68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f789c1a-3bdf-4ef3-89b1-439a32bfc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "glassdoor_filter = '?sort.sortType=RD&sort.ascending=false&filter.iso3Language=eng&filter.employmentStatus=PART_TIME&filter.employmentStatus=INTERN&filter.employmentStatus=REGULAR'\n",
    "wb = load_workbook('status.xlsx', data_only=True)\n",
    "sheet = wb.worksheets[0]\n",
    "companies_cells, number_options_cells, links_cells, pages_cells = get_status()\n",
    "companies = cells_to_list(companies_cells)\n",
    "number_options = cells_to_list(number_options_cells)\n",
    "links = cells_to_list(links_cells)\n",
    "links_filtered = [link + glassdoor_filter if link != '/' else '/' for link in links]\n",
    "pages = cells_to_list(pages_cells)\n",
    "\n",
    "for i in range(len(companies)):\n",
    "    if (links_filtered[i] != '_') and (links_filtered[i] != '/'):\n",
    "        if pages[i] == '_':\n",
    "            try:\n",
    "                url_to_df(links_filtered[i], i=i, company=companies[i], s=6, page=1) #You can add max_date\n",
    "            except:\n",
    "                time.sleep(random.uniform(20, 30))\n",
    "                url_to_df(links_filtered[i], i=i, company=companies[i], s=6, page=1) #You can add max_date\n",
    "        elif pages[i] == 'done':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                url_to_df(links_filtered[i], i=i, company=companies[i], s=6, page=pages[i]) #You can add max_date\n",
    "            except:\n",
    "                time.sleep(random.uniform(20, 30))\n",
    "                url_to_df(links_filtered[i], i=i, company=companies[i], s=6, page=pages[i]) #You can add max_date\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9f0b1-eaff-4c49-b5d7-774b5a859011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0c78b-7a42-4a78-80c9-75d947799fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a537ff1-1684-4f3d-a1d5-2d0a1f1e6ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe9e4-e928-41e3-aaef-1c174f911a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef3204-1d14-4108-89ac-ea6efec511be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d189cf-b1bf-4e33-aab6-5e76809dfad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db35433-f314-4892-b9f9-a7130fc87813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92a4b0-fbd8-43b5-b1c0-cc92d13bd666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
